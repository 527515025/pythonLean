# -*- coding: utf-8 -*-
# 手写数字识别
# 准确度 0.8802
import 手写数字识别.input_data  
import tensorflow as tf
mnist = 手写数字识别.input_data.read_data_sets("手写数字识别/MNIST_data/", one_hot=True)  

def compute_accuracy(v_xs,v_ys):
	# 定义 prediction 为全局变量
	global prediction
	# 将 xs data 在 prediction 中生成预测值，预测值也是一个 1*10 的矩阵 中每个值的概率，并不是一个0-9 的值，是0-9 每个值的概率 ，比如说3这个位置的概率最高，那么预测3就是这个图片的值
	y_pre = sess.run(prediction, feed_dict={xs: v_xs,keep_prob: 1})
	# 对比我的预测值y_pre 和真实数据 v_ys 的差别
	correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))
	# 计算我这一组数据中有多少个预测是对的，多少个是错的
	accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
	# result 是一个百分比，百分比越高，预测越准确
	result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys,keep_prob: 1})
	return result   

#我们定义Weight变量，输入shape，返回变量的参数。其中我们使用tf.truncted_normal产生随机变量来进行初始化
def weight_variable(shape):
	#google 也是用truncted_normal 来产生随机变量
	initial = tf.truncated_normal(shape,stddev=0.1)
	return tf.Variable(initial)
#定义biase变量，输入shape ,返回变量的一些参数。其中我们使用tf.constant常量函数来进行初始化
def bias_variable(shape):
	#定义成 0.1之后才会从0.1变到其他的值， bias通常用正直比较好，所以我们用0.1
	initial = tf.constant(0.1,shape=shape)
	return tf.Variable(initial)

#定义卷积，tf.nn.conv2d函数是tensoflow里面的二维的卷积函数，x是图片的所有参数，W是此卷积层的权重
def conv2d(x,W):
	#定义步长strides=[1,1,1,1]值，strides[0]和strides[3]的两个1是默认值，中间两个1代表padding时在x方向运动一步，y方向运动一步
	#padding采用的方式是SAME。
	return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')

#定义池化pooling  x 为conv2d 的返回 ,在pooling 阶段图片的长和宽被减小
def max_poo_2x2(x):
	#步长strides=[1,2,2,1]值，strides[0]和strides[3]的两个1是默认值，中间两个2代表padding时在x方向运动两步，y方向运动两步
	return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')

xs = tf.placeholder(tf.float32,[None, 784]) #图像输入向量  每个图片有784 （28 ＊28） 个像素点
ys = tf.placeholder(tf.float32, [None,10]) #每个例子有10 个输出
keep_prob = tf.placeholder(tf.float32)



# 处理输入图片的信息 把xs的形状变成[-1,28,28,1]，-1代表先不考虑输入的图片例子多少这个维度，28 28 代表的是长和宽 后面的1是channel的数量，因为我们输入的图片是黑白的，因此channel是1，例如如果是RGB图像，那么channel就是3
xs_image = tf.reshape(xs,[-1,28,28,1])
# print(xs_image.shape)

# 第一层##
# 定义本层的Weight,本层我们的卷积核patch的大小是5x5，因为黑白图片channel是1 是图片的厚度 所以输入是1 彩色的厚度是3，输出是32个featuremap
W_conv1 = weight_variable([5,5,1,32])
# 大小是32个长度，因此我们传入它的shape为[32]
b_conv1= bias_variable([32])
# 卷积神经网络的第一个卷积层, 对h_conv1进行非线性处理，也就是激活函数来处理 tf.nn.relu（修正线性单元）来处理，要注意的是，因为采用了SAME的padding方式，
# 输出图片的大小没有变化依然是28x28，只是厚度变厚了，因此现在的输出大小就变成了28x28x32
h_conv1 =tf.nn.relu(conv2d(xs_image,W_conv1) + b_conv1)
# 经过pooling的处理，输出大小就变为了14x14x32
h_pool1 = max_poo_2x2(h_conv1)

# 第二层##
# 定义本层的Weight,本层我们的卷积核patch的大小是5x5，32 是图片的厚度，输出是64个featuremap
W_conv2 = weight_variable([5,5,32,64])
# 大小是64个长度，因此我们传入它的shape为[64]
b_conv2= bias_variable([64])
# 卷积神经网络的第二个卷积层, 对h_conv2进行非线性处理，也就是激活函数来处理 tf.nn.relu（修正线性单元）来处理，要注意的是，因为采用了SAME的padding方式，
# 输出图片的大小没有变化依然是14x14，只是厚度变厚了，因此现在的输出大小就变成了14x14x64
h_conv2 =tf.nn.relu(conv2d(h_pool1,W_conv2) + b_conv2)
# 经过pooling的处理，输出大小就变为了7x7x64
h_pool2 = max_poo_2x2(h_conv2)


#func1 layer##
# 参考上面注释
W_fc1 = weight_variable([7*7*64,1024])
b_fc1 = bias_variable([1024])
# 通过tf.reshape()将h_pool2的输出值从一个三维的变为一维的数据, -1表示先不考虑输入图片例子维度, 将上一个输出结果展平，
h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64]) #[n_samples,7,7,64]->>[n_samples,7*7*64]

# 将展平后的h_pool1_flat与本层的W_fc1相乘（注意这个时候不是卷积了）
h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1)
# 考虑过拟合问题，可以加一个dropout的处理
h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)


#func2 layer##
W_fc2 = weight_variable([1024,10])
b_fc2 = bias_variable([10])

# 预测值，prediction 用softmax 处理 计算概率
prediction = tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2)+b_fc2)


#loss函数（即最优化目标函数）选用交叉熵函数。交叉熵用来衡量预测值和真实值的相似程度，如果完全相同，它们的交叉熵等于零 ,所以loss 越小 学的好
#分类一般都是 softmax＋ cross_entropy
cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),
reduction_indices=[1]))
# cross_entropy = -tf.reduce_sum(ys*tf.log(prediction))  

#train方法（最优化算法）AdamOptimizer()作为我们的优化器进行优化 ，AdamOptimizer 适合比较庞大的系统 ，1e-4 0.0004
train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)
sess = tf.Session()

# 初始化变量
init= tf.global_variables_initializer()
sess.run(init)

for i in range(1000):
	#开始train，每次只取100张图片，免得数据太多训练太慢
	batch_xs, batch_ys = mnist.train.next_batch(100)
	sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys,keep_prob: 0.5})
	if i % 50 == 0:
		print(compute_accuracy(
            mnist.test.images, mnist.test.labels))